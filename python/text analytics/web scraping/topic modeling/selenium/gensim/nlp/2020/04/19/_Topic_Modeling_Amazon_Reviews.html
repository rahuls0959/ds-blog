<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Topic Modeling of Product Reviews on Amazon Scraped using Selenium in Python | Home</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Topic Modeling of Product Reviews on Amazon Scraped using Selenium in Python" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A tutorial demonstrating scraping product reviews from Amazon and extracting and analysing the topics from the text data." />
<meta property="og:description" content="A tutorial demonstrating scraping product reviews from Amazon and extracting and analysing the topics from the text data." />
<link rel="canonical" href="https://rahuls0959.github.io/ds-blog/python/text%20analytics/web%20scraping/topic%20modeling/selenium/gensim/nlp/2020/04/19/_Topic_Modeling_Amazon_Reviews.html" />
<meta property="og:url" content="https://rahuls0959.github.io/ds-blog/python/text%20analytics/web%20scraping/topic%20modeling/selenium/gensim/nlp/2020/04/19/_Topic_Modeling_Amazon_Reviews.html" />
<meta property="og:site_name" content="Home" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-04-19T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"A tutorial demonstrating scraping product reviews from Amazon and extracting and analysing the topics from the text data.","@type":"BlogPosting","headline":"Topic Modeling of Product Reviews on Amazon Scraped using Selenium in Python","url":"https://rahuls0959.github.io/ds-blog/python/text%20analytics/web%20scraping/topic%20modeling/selenium/gensim/nlp/2020/04/19/_Topic_Modeling_Amazon_Reviews.html","datePublished":"2020-04-19T00:00:00-05:00","dateModified":"2020-04-19T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://rahuls0959.github.io/ds-blog/python/text%20analytics/web%20scraping/topic%20modeling/selenium/gensim/nlp/2020/04/19/_Topic_Modeling_Amazon_Reviews.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/ds-blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://rahuls0959.github.io/ds-blog/feed.xml" title="Home" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-163975149-1','auto');ga('require','displayfeatures');ga('send','pageview');</script>

<link rel="shortcut icon" type="image/x-icon" href="/ds-blog/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Topic Modeling of Product Reviews on Amazon Scraped using Selenium in Python | Home</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Topic Modeling of Product Reviews on Amazon Scraped using Selenium in Python" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A tutorial demonstrating scraping product reviews from Amazon and extracting and analysing the topics from the text data." />
<meta property="og:description" content="A tutorial demonstrating scraping product reviews from Amazon and extracting and analysing the topics from the text data." />
<link rel="canonical" href="https://rahuls0959.github.io/ds-blog/python/text%20analytics/web%20scraping/topic%20modeling/selenium/gensim/nlp/2020/04/19/_Topic_Modeling_Amazon_Reviews.html" />
<meta property="og:url" content="https://rahuls0959.github.io/ds-blog/python/text%20analytics/web%20scraping/topic%20modeling/selenium/gensim/nlp/2020/04/19/_Topic_Modeling_Amazon_Reviews.html" />
<meta property="og:site_name" content="Home" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-04-19T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"A tutorial demonstrating scraping product reviews from Amazon and extracting and analysing the topics from the text data.","@type":"BlogPosting","headline":"Topic Modeling of Product Reviews on Amazon Scraped using Selenium in Python","url":"https://rahuls0959.github.io/ds-blog/python/text%20analytics/web%20scraping/topic%20modeling/selenium/gensim/nlp/2020/04/19/_Topic_Modeling_Amazon_Reviews.html","datePublished":"2020-04-19T00:00:00-05:00","dateModified":"2020-04-19T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://rahuls0959.github.io/ds-blog/python/text%20analytics/web%20scraping/topic%20modeling/selenium/gensim/nlp/2020/04/19/_Topic_Modeling_Amazon_Reviews.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://rahuls0959.github.io/ds-blog/feed.xml" title="Home" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-163975149-1','auto');ga('require','displayfeatures');ga('send','pageview');</script>



<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head><body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/ds-blog/">Home</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/ds-blog/about/">About Me</a><a class="page-link" href="/ds-blog/search/">Search</a><a class="page-link" href="/ds-blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Topic Modeling of Product Reviews on Amazon Scraped using Selenium in Python</h1><p class="page-description">A tutorial demonstrating scraping product reviews from Amazon and extracting and analysing the topics from the text data.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-04-19T00:00:00-05:00" itemprop="datePublished">
        Apr 19, 2020
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      13 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/ds-blog/categories/#python">python</a>
        &nbsp;
      
        <a class="category-tags-link" href="/ds-blog/categories/#text analytics">text analytics</a>
        &nbsp;
      
        <a class="category-tags-link" href="/ds-blog/categories/#web scraping">web scraping</a>
        &nbsp;
      
        <a class="category-tags-link" href="/ds-blog/categories/#topic modeling">topic modeling</a>
        &nbsp;
      
        <a class="category-tags-link" href="/ds-blog/categories/#selenium">selenium</a>
        &nbsp;
      
        <a class="category-tags-link" href="/ds-blog/categories/#gensim">gensim</a>
        &nbsp;
      
        <a class="category-tags-link" href="/ds-blog/categories/#nlp">nlp</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/rahuls0959/ds-blog/tree/master/_notebooks/2020-04-20_Topic_Modeling_Amazon_Reviews.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/ds-blog/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          
          <div class="px-2">
    <a href="https://colab.research.google.com/github/rahuls0959/ds-blog/blob/master/_notebooks/2020-04-20_Topic_Modeling_Amazon_Reviews.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/ds-blog/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#Introduction">Introduction </a></li>
<li class="toc-entry toc-h2"><a href="#Web-Scraping">Web Scraping </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Import-Packages">Import Packages </a></li>
<li class="toc-entry toc-h3"><a href="#Script-for-Scraping">Script for Scraping </a></li>
<li class="toc-entry toc-h3"><a href="#Data-Cleaning">Data Cleaning </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Topic-Modeling-using-LDA">Topic Modeling using LDA </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Data-Pre-processing">Data Pre-processing </a></li>
<li class="toc-entry toc-h3"><a href="#Preparign-Document-Term-Matrix">Preparign Document-Term-Matrix </a></li>
<li class="toc-entry toc-h3"><a href="#Running-LDA-Model">Running LDA Model </a></li>
<li class="toc-entry toc-h3"><a href="#Extracting-Topics">Extracting Topics </a></li>
<li class="toc-entry toc-h3"><a href="#Visualization-of-LDA-Model">Visualization of LDA Model </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Endnotes">Endnotes </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-04-20_Topic_Modeling_Amazon_Reviews.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Introduction">
<a class="anchor" href="#Introduction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introduction<a class="anchor-link" href="#Introduction"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The blog covers the step-by-step process to scrap product reviews from Amazon webpage and analysing main topics from the extracted data. We will scrap 1000 reviews from the Amazon for Apple iPhone 11 64GB. With this data, we will convert each review doc into bag-of words for applying the topic modeling algorithm. We will be using Latent Dirichlet Allocation (LDA) algorithm in this tutorial. The main python libraries used are:</p>
<ul>
<li>selenium: Selenium is a portable framework for testing web applications. We will be using this to interact with the browser and open URLs.</li>
<li>gensim: Gensim is an open-source library for unsupervised topic modeling and natural language processing, using modern statistical machine learning.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Web-Scraping">
<a class="anchor" href="#Web-Scraping" aria-hidden="true"><span class="octicon octicon-link"></span></a>Web Scraping<a class="anchor-link" href="#Web-Scraping"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Web scraping is a technique for extracting information from the internet automatically using a software that simulates human web surfing.Web scraping helps us extract large volumes of data about customers, products, people, stock markets, etc. It is usually difficult to get this kind of information on a large scale using traditional data collection methods. We can utilize the data collected from a website such as e-commerce portal, social media channels to understand customer behaviors and sentiments, buying patterns, and brand attribute associations which are critical insights for any business.</p>
<p>The first and foremost thing while scraping a website is to understand the structure of the website. We will be scraping the reviews for Apple iPhone 11 64GB on Amazon.in website. We will scrape 1000 reviews from different users across multiple pages. We will scrape user name, date of review and review and export it into a csv file for any further analysis.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Import-Packages">
<a class="anchor" href="#Import-Packages" aria-hidden="true"><span class="octicon octicon-link"></span></a>Import Packages<a class="anchor-link" href="#Import-Packages"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Install selenium package (if not already worked with before) using command '!pip install selenium'</li>
<li>Import webdriver from selenium in the notebook which we use to open an instance of Chrome browser.</li>
<li>The executable file for launching Chrome 'chromedriver.exe' should be in the same folder as the notebook.</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Importing packages</span>
<span class="kn">from</span> <span class="nn">selenium</span> <span class="kn">import</span> <span class="n">webdriver</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Script-for-Scraping">
<a class="anchor" href="#Script-for-Scraping" aria-hidden="true"><span class="octicon octicon-link"></span></a>Script for Scraping<a class="anchor-link" href="#Script-for-Scraping"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The below code opens the new chrome browser window and open our website with the url link provided. By the way, chrome knows that you are accessing it through an automated software!
<img src="/ds-blog/images/copied_from_nb/img/chrome.png" alt=""></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">driver</span> <span class="o">=</span> <span class="n">webdriver</span><span class="o">.</span><span class="n">Chrome</span><span class="p">(</span><span class="s1">'chromedriver.exe'</span><span class="p">)</span>
<span class="n">url</span> <span class="o">=</span> <span class="s1">'https://www.amazon.in/Apple-iPhone-11-64GB-White/product-reviews/B07XVMCLP7/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&amp;reviewerType=all_reviews&amp;pageNumber1'</span>
<span class="n">driver</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We will inspect 3 items (user id, date and comment) on our web page and understand how we can extract them.</p>
<ul>
<li>
<p>Xpath for User id: Inspecting the userid, we can see the highlighted text represents the XML code for user id.The XML path (XPath)for the userid is shown below:</p>
<p>//*[@id="customer_review-RBOIMRTKIYBBR"]/div[1]/a/div[2]/span</p>
</li>
</ul>
<p><img src="/ds-blog/images/copied_from_nb/img/chrome-2.png" alt=""></p>
<p>There is an interesting thing to note here that the XML path contains a review id, which uniquely denotes each review on the website. This will be very helpful as we try to recursively scrape multiple comments.</p>
<ul>
<li>Xpath for Date &amp; review: Similarily, we will find the XPaths for date and review. </li>
<li>Selenium has a function called “find_elements_by_xpath”. We will pass our XPath into this function and get a selenium element. Once we have the element, we can extract the text inside our XPath using the ‘text’ function.</li>
<li>We will recursively run the code for different review id and extract user id, date and review for each review id. Also, we will recursively go to next pages by simply changing the page numbers in the url to extract more comments until we get the desired number of comments.</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">driver</span> <span class="o">=</span> <span class="n">webdriver</span><span class="o">.</span><span class="n">Chrome</span><span class="p">(</span><span class="s1">'chromedriver.exe'</span><span class="p">)</span>

<span class="c1">#Creating empty data frame to store user_id, dates and comments from ~5K users.</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'date'</span><span class="p">,</span><span class="s1">'username'</span><span class="p">,</span><span class="s1">'review'</span><span class="p">])</span>

<span class="n">j</span> <span class="o">=</span> <span class="mi">1</span>
<span class="k">while</span> <span class="p">(</span><span class="n">j</span><span class="o">&lt;=</span><span class="mi">130</span><span class="p">):</span>
    <span class="c1"># Running while loop only till we get 1K reviews</span>
    <span class="k">if</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">&lt;</span><span class="mi">1000</span><span class="p">):</span>
        <span class="n">url</span> <span class="o">=</span> <span class="s1">'https://www.amazon.in/Apple-iPhone-11-64GB-White/product-reviews/B07XVMCLP7/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&amp;reviewerType=all_reviews&amp;pageNumber='</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">j</span><span class="p">)</span>
        <span class="n">driver</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
        <span class="n">ids</span> <span class="o">=</span> <span class="n">driver</span><span class="o">.</span><span class="n">find_elements_by_xpath</span><span class="p">(</span><span class="s2">"//*[contains(@id,'customer_review-')]"</span><span class="p">)</span>
        <span class="n">review_ids</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ids</span><span class="p">:</span>
            <span class="n">review_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="o">.</span><span class="n">get_attribute</span><span class="p">(</span><span class="s1">'id'</span><span class="p">))</span>

        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">review_ids</span><span class="p">:</span>
            <span class="c1">#Extract dates from for each user on a page</span>
            <span class="n">date_element</span> <span class="o">=</span> <span class="n">driver</span><span class="o">.</span><span class="n">find_elements_by_xpath</span><span class="p">(</span><span class="s1">'//*[@id="'</span> <span class="o">+</span> <span class="n">x</span> <span class="o">+</span><span class="s1">'"]/span'</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">date</span> <span class="o">=</span> <span class="n">date_element</span><span class="o">.</span><span class="n">text</span>

            <span class="c1">#Extract user ids from each user on a page</span>
            <span class="n">username_element</span> <span class="o">=</span> <span class="n">driver</span><span class="o">.</span><span class="n">find_elements_by_xpath</span><span class="p">(</span><span class="s1">'//*[@id="'</span> <span class="o">+</span> <span class="n">x</span> <span class="o">+</span><span class="s1">'"]/div[1]/a/div[2]/span'</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">username</span> <span class="o">=</span> <span class="n">username_element</span><span class="o">.</span><span class="n">text</span>

            <span class="c1">#Extract Message for each user on a page</span>
            <span class="n">review_element</span> <span class="o">=</span> <span class="n">driver</span><span class="o">.</span><span class="n">find_elements_by_xpath</span><span class="p">(</span><span class="s1">'//*[@id="'</span> <span class="o">+</span> <span class="n">x</span> <span class="o">+</span><span class="s1">'"]/div[4]'</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">review</span> <span class="o">=</span> <span class="n">review_element</span><span class="o">.</span><span class="n">text</span>
            
           <span class="c1">#Adding date, userid and comment for each user in a dataframe    </span>
            <span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)]</span> <span class="o">=</span> <span class="p">[</span><span class="n">date</span><span class="p">,</span><span class="n">username</span><span class="p">,</span><span class="n">review</span><span class="p">]</span>
        <span class="n">j</span><span class="o">=</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">break</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Data-Cleaning">
<a class="anchor" href="#Data-Cleaning" aria-hidden="true"><span class="octicon octicon-link"></span></a>Data Cleaning<a class="anchor-link" href="#Data-Cleaning"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>We perform few data cleaning operations such as replacing line breaks with a space and copy the data into .csv file which can be used for further analysis.</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">copy</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">remove_space</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">s</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">,</span><span class="s2">" "</span><span class="p">)</span>

<span class="n">data</span><span class="p">[</span><span class="s1">'review'</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">'review'</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">remove_space</span><span class="p">)</span>
<span class="n">data</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">'amazon_reviews.csv'</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">','</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'amazon_reviews.csv'</span><span class="p">,</span><span class="n">index_col</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">data</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>date</th>
      <th>username</th>
      <th>review</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>Reviewed in India on 20 October 2019</td>
      <td>Suman Biswas</td>
      <td>May be my first negative review about the prod...</td>
    </tr>
    <tr>
      <td>1</td>
      <td>Reviewed in India on 17 September 2019</td>
      <td>Kaushik Bajaj</td>
      <td>It's very expensive but the quality you get is...</td>
    </tr>
    <tr>
      <td>2</td>
      <td>Reviewed in India on 29 September 2019</td>
      <td>Sunny Kumar</td>
      <td>The iPhone design is good and the camera quali...</td>
    </tr>
    <tr>
      <td>3</td>
      <td>Reviewed in India on 30 September 2019</td>
      <td>shanu Kumar</td>
      <td>Awesome Phone. Nice upgrade from iPhone 6s to ...</td>
    </tr>
    <tr>
      <td>4</td>
      <td>Reviewed in India on 14 October 2019</td>
      <td>Amazon Customer</td>
      <td>My Phone is Producing Too Much Heat Even Didn’...</td>
    </tr>
    <tr>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <td>995</td>
      <td>Reviewed in India on 1 March 2020</td>
      <td>Amazon Customer</td>
      <td>❤️</td>
    </tr>
    <tr>
      <td>996</td>
      <td>Reviewed in India on 9 March 2020</td>
      <td>Chirag Patel</td>
      <td>Ok</td>
    </tr>
    <tr>
      <td>997</td>
      <td>Reviewed in India on 11 March 2020</td>
      <td>chintu</td>
      <td>Excellent</td>
    </tr>
    <tr>
      <td>998</td>
      <td>Reviewed in India on 8 March 2020</td>
      <td>Amazon Customer</td>
      <td>Excellent</td>
    </tr>
    <tr>
      <td>999</td>
      <td>Reviewed in India on 8 March 2020</td>
      <td>Dheeraj v.</td>
      <td>Flawless!</td>
    </tr>
  </tbody>
</table>
<p>1000 rows × 3 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Since the goal of further analysis is to perform topic modeling, we will solely focus on the review text, and drop other metadata columns i.e. date and user name.</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Remove the columns</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">'date'</span><span class="p">,</span> <span class="s1">'username'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># Print out the data</span>
<span class="n">data</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>review</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>May be my first negative review about the prod...</td>
    </tr>
    <tr>
      <td>1</td>
      <td>It's very expensive but the quality you get is...</td>
    </tr>
    <tr>
      <td>2</td>
      <td>The iPhone design is good and the camera quali...</td>
    </tr>
    <tr>
      <td>3</td>
      <td>Awesome Phone. Nice upgrade from iPhone 6s to ...</td>
    </tr>
    <tr>
      <td>4</td>
      <td>My Phone is Producing Too Much Heat Even Didn’...</td>
    </tr>
    <tr>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <td>995</td>
      <td>❤️</td>
    </tr>
    <tr>
      <td>996</td>
      <td>Ok</td>
    </tr>
    <tr>
      <td>997</td>
      <td>Excellent</td>
    </tr>
    <tr>
      <td>998</td>
      <td>Excellent</td>
    </tr>
    <tr>
      <td>999</td>
      <td>Flawless!</td>
    </tr>
  </tbody>
</table>
<p>1000 rows × 1 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Topic-Modeling-using-LDA">
<a class="anchor" href="#Topic-Modeling-using-LDA" aria-hidden="true"><span class="octicon octicon-link"></span></a>Topic Modeling using LDA<a class="anchor-link" href="#Topic-Modeling-using-LDA"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Topic modeling is a type of statistical modeling for discovering the abstract “topics” that occur in a collection of documents. Latent Dirichlet Allocation (LDA) is an example of topic model and is used to classify text in a document to a particular topic. LDA is a generative probabilistic model that assumes each topic is a mixture over an underlying set of words, and each document is a mixture of over a set of topic probabilities.</p>
<p>Illustration of LDA input/output workflow (Credit: <a href="http://chdoig.github.io/pytexas2015-topic-modeling/#/3/4">http://chdoig.github.io/pytexas2015-topic-modeling/#/3/4</a>)
<img src="/ds-blog/images/copied_from_nb/img/lda-1.png" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Data-Pre-processing">
<a class="anchor" href="#Data-Pre-processing" aria-hidden="true"><span class="octicon octicon-link"></span></a>Data Pre-processing<a class="anchor-link" href="#Data-Pre-processing"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We will preprocess the review data using gensim library. Few of the actions performed by preprocess_string as follows:</p>
<ul>
<li>Tokenization: Split the text into sentences and the sentences into words. Lowercase the words and remove punctuation.</li>
<li>All stopwords are removed.</li>
<li>Words are lemmatized: words in third person are changed to first person and verbs in past and future tenses are changed into present. </li>
<li>Words are stemmed: words are reduced to their root form.</li>
</ul>
<p>Please see below the output after pre-processing for one of the reviews.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">gensim</span>
<span class="kn">from</span> <span class="nn">gensim.parsing.preprocessing</span> <span class="kn">import</span> <span class="n">preprocess_string</span>

<span class="c1"># print unprocessed text</span>
<span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">review</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="c1"># print processed text</span>
<span class="nb">print</span><span class="p">(</span><span class="n">preprocess_string</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">review</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>May be my first negative review about the product &amp; Amazon both. I was much elated to receive the iPhone 11 so fast, next day of dispatch i.e. 28/09/19, but the thing I got started heating up every now and then. Contacted Applecare, just to be consoled that it's quite normal. As it continued, tried to return the product by speaking to Amazon customer support but in vain. Some body called me back to convey that only Apple will decide which one to take back. Why is then Amazon took up the sacred duty of selling such an item which they can't exchange/ have no control ? The product developed new issues like proximity sensor malfunction and last but most importantly loosing mobile network every other minute(even had two software updates). It was handed over to the Apple ASP as the return window closed on 10/10/19 (what use it was for??) and diagnosed as having issues and has further been sent to Apple repair facility at Bengaluru. So I'm here w/out my first iPhone after using it(suffering for??) just a little over 2 weeks and the CREDIT GOES TO AMAZON !! Bravo, keep it up Amazon.
['neg', 'review', 'product', 'amazon', 'elat', 'receiv', 'iphon', 'fast', 'dai', 'dispatch', 'thing', 'got', 'start', 'heat', 'contact', 'applecar', 'consol', 'normal', 'continu', 'tri', 'return', 'product', 'speak', 'amazon', 'custom', 'support', 'vain', 'bodi', 'call', 'convei', 'appl', 'decid', 'amazon', 'took', 'sacr', 'duti', 'sell', 'item', 'exchang', 'control', 'product', 'develop', 'new', 'issu', 'like', 'proxim', 'sensor', 'malfunct', 'importantli', 'loos', 'mobil', 'network', 'minut', 'softwar', 'updat', 'hand', 'appl', 'asp', 'return', 'window', 'close', 'us', 'diagnos', 'have', 'issu', 'sent', 'appl', 'repair', 'facil', 'bengaluru', 'iphon', 'suffer', 'littl', 'week', 'credit', 'goe', 'amazon', 'bravo', 'amazon']
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">processed_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">'review'</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">preprocess_string</span><span class="p">)</span>
<span class="n">processed_data</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>0      [neg, review, product, amazon, elat, receiv, i...
1                                [expens, qualiti, osum]
2      [iphon, design, good, camera, qualiti, awesom,...
3      [awesom, phone, nice, upgrad, iphon, iphon, lo...
4      [phone, produc, heat, didn’t, sim, half, hour,...
                             ...                        
995                                                   []
996                                                   []
997                                              [excel]
998                                              [excel]
999                                           [flawless]
Name: review, Length: 1000, dtype: object</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Preparign-Document-Term-Matrix">
<a class="anchor" href="#Preparign-Document-Term-Matrix" aria-hidden="true"><span class="octicon octicon-link"></span></a>Preparign Document-Term-Matrix<a class="anchor-link" href="#Preparign-Document-Term-Matrix"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Gensim requires that tokens be converted to a dictionary. In this instance a dictionary is a mapping between words and their integer IDs. We then create a  Document-Term-Matrix where we use Bag-of-Words approach returning the vector of word and its frequency (number of occurences in the document) for each document.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Importing Gensim</span>
<span class="kn">import</span> <span class="nn">gensim</span>
<span class="kn">from</span> <span class="nn">gensim</span> <span class="kn">import</span> <span class="n">corpora</span>

<span class="c1"># Creating the term dictionary of our list of documents (corpus), where every unique term is assigned an index. </span>
<span class="n">dictionary</span> <span class="o">=</span> <span class="n">corpora</span><span class="o">.</span><span class="n">Dictionary</span><span class="p">(</span><span class="n">processed_data</span><span class="p">)</span>

<span class="c1"># Converting list of documents (corpus) into Document Term Matrix using dictionary prepared above.</span>
<span class="n">doc_term_matrix</span> <span class="o">=</span> <span class="p">[</span><span class="n">dictionary</span><span class="o">.</span><span class="n">doc2bow</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">processed_data</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Running-LDA-Model">
<a class="anchor" href="#Running-LDA-Model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Running LDA Model<a class="anchor-link" href="#Running-LDA-Model"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We will now run the LDA Model. The number of topics you give is largely a guess/arbitrary. The model assumes the document contains that many topics. However, finding the number of topics explaining the data is a optimisation problem and can be found by 'Coherence Model'.</p>
<p>Here, we have used number of topics = 3</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#RUN THE MODEL</span>
<span class="c1"># Creating the object for LDA model using gensim library</span>
<span class="n">Lda</span> <span class="o">=</span> <span class="n">gensim</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">ldamodel</span><span class="o">.</span><span class="n">LdaModel</span>

<span class="c1"># Running and Trainign LDA model on the document term matrix.</span>
<span class="n">TOPIC_CNT</span><span class="o">=</span> <span class="mi">3</span>
<span class="n">ldamodel</span> <span class="o">=</span> <span class="n">Lda</span><span class="p">(</span><span class="n">doc_term_matrix</span><span class="p">,</span> <span class="n">num_topics</span><span class="o">=</span><span class="n">TOPIC_CNT</span><span class="p">,</span> <span class="n">id2word</span> <span class="o">=</span> <span class="n">dictionary</span><span class="p">,</span> <span class="n">passes</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can then see the weights of top 20 words in each topic, which can help us to explain the topic.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Results</span>
<span class="n">topics</span><span class="o">=</span> <span class="n">ldamodel</span><span class="o">.</span><span class="n">print_topics</span><span class="p">(</span><span class="n">num_topics</span><span class="o">=</span><span class="n">TOPIC_CNT</span><span class="p">,</span> <span class="n">num_words</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">topics</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[(0,
  '0.066*"phone" + 0.047*"good" + 0.017*"appl" + 0.015*"best" + 0.014*"charger" + 0.010*"time" + 0.010*"work" + 0.010*"issu" + 0.009*"charg" + 0.008*"iphon" + 0.008*"camera" + 0.007*"screen" + 0.007*"get" + 0.007*"purchas" + 0.006*"mobil" + 0.006*"android" + 0.006*"batteri" + 0.006*"heat" + 0.006*"us" + 0.006*"like"'),
 (1,
  '0.043*"iphon" + 0.038*"batteri" + 0.037*"camera" + 0.036*"phone" + 0.026*"awesom" + 0.026*"good" + 0.024*"best" + 0.024*"qualiti" + 0.024*"life" + 0.023*"great" + 0.011*"displai" + 0.010*"amaz" + 0.010*"upgrad" + 0.009*"perform" + 0.009*"love" + 0.008*"superb" + 0.008*"bui" + 0.008*"dai" + 0.007*"face" + 0.006*"better"'),
 (2,
  '0.064*"product" + 0.030*"amazon" + 0.028*"appl" + 0.023*"nice" + 0.015*"phone" + 0.015*"bui" + 0.015*"monei" + 0.013*"excel" + 0.011*"deliveri" + 0.010*"got" + 0.010*"time" + 0.010*"iphon" + 0.009*"devic" + 0.009*"perfect" + 0.009*"worth" + 0.009*"valu" + 0.009*"thank" + 0.009*"happi" + 0.008*"receiv" + 0.007*"good"')]</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Extracting-Topics">
<a class="anchor" href="#Extracting-Topics" aria-hidden="true"><span class="octicon octicon-link"></span></a>Extracting Topics<a class="anchor-link" href="#Extracting-Topics"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can identify the follow topics emerging out of reviews of Amazon iPhone 11 64GB on Amazon:</p>
<ul>
<li>Topic #1: There seems to discussion of heat/ charging issue with the product.</li>
<li>Topic #2: The discussion on iPhone's features such as camera, display, battery.</li>
<li>Topic #3: iPhone being value for money and discussuin on Amazon delivery.</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">word_dict</span> <span class="o">=</span> <span class="p">{};</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">TOPIC_CNT</span><span class="p">):</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">ldamodel</span><span class="o">.</span><span class="n">show_topic</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">topn</span> <span class="o">=</span> <span class="mi">20</span><span class="p">)</span>
    <span class="n">word_dict</span><span class="p">[</span><span class="s1">'Topic #'</span> <span class="o">+</span> <span class="s1">'</span><span class="si">{:2d}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">words</span><span class="p">]</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">word_dict</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Topic # 1</th>
      <th>Topic # 2</th>
      <th>Topic # 3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>phone</td>
      <td>iphon</td>
      <td>product</td>
    </tr>
    <tr>
      <td>1</td>
      <td>good</td>
      <td>batteri</td>
      <td>amazon</td>
    </tr>
    <tr>
      <td>2</td>
      <td>appl</td>
      <td>camera</td>
      <td>appl</td>
    </tr>
    <tr>
      <td>3</td>
      <td>best</td>
      <td>phone</td>
      <td>nice</td>
    </tr>
    <tr>
      <td>4</td>
      <td>charger</td>
      <td>awesom</td>
      <td>phone</td>
    </tr>
    <tr>
      <td>5</td>
      <td>time</td>
      <td>good</td>
      <td>bui</td>
    </tr>
    <tr>
      <td>6</td>
      <td>work</td>
      <td>best</td>
      <td>monei</td>
    </tr>
    <tr>
      <td>7</td>
      <td>issu</td>
      <td>qualiti</td>
      <td>excel</td>
    </tr>
    <tr>
      <td>8</td>
      <td>charg</td>
      <td>life</td>
      <td>deliveri</td>
    </tr>
    <tr>
      <td>9</td>
      <td>iphon</td>
      <td>great</td>
      <td>got</td>
    </tr>
    <tr>
      <td>10</td>
      <td>camera</td>
      <td>displai</td>
      <td>time</td>
    </tr>
    <tr>
      <td>11</td>
      <td>screen</td>
      <td>amaz</td>
      <td>iphon</td>
    </tr>
    <tr>
      <td>12</td>
      <td>get</td>
      <td>upgrad</td>
      <td>devic</td>
    </tr>
    <tr>
      <td>13</td>
      <td>purchas</td>
      <td>perform</td>
      <td>perfect</td>
    </tr>
    <tr>
      <td>14</td>
      <td>mobil</td>
      <td>love</td>
      <td>worth</td>
    </tr>
    <tr>
      <td>15</td>
      <td>android</td>
      <td>superb</td>
      <td>valu</td>
    </tr>
    <tr>
      <td>16</td>
      <td>batteri</td>
      <td>bui</td>
      <td>thank</td>
    </tr>
    <tr>
      <td>17</td>
      <td>heat</td>
      <td>dai</td>
      <td>happi</td>
    </tr>
    <tr>
      <td>18</td>
      <td>us</td>
      <td>face</td>
      <td>receiv</td>
    </tr>
    <tr>
      <td>19</td>
      <td>like</td>
      <td>better</td>
      <td>good</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The below code provide the % of topics a document is about. This helps to find the dominant topic in each review.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">doc_to_topic</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">doc_term_matrix</span><span class="p">)):</span>
    <span class="n">top_topics</span> <span class="o">=</span> <span class="n">ldamodel</span><span class="o">.</span><span class="n">get_document_topics</span><span class="p">(</span><span class="n">doc_term_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">minimum_probability</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
    <span class="n">topic_vec</span> <span class="o">=</span> <span class="p">[</span><span class="n">top_topics</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">TOPIC_CNT</span><span class="p">)]</span>
    <span class="n">doc_to_topic</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">topic_vec</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Dataframe of topic</span>
<span class="n">document_topics</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">doc_to_topic</span><span class="p">)</span>
<span class="n">document_topics</span> <span class="o">=</span> <span class="n">document_topics</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">document_topics</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">document_topics</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>
<span class="n">document_topics</span> <span class="o">=</span> <span class="n">document_topics</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="s1">'Topic #'</span> <span class="o">+</span> <span class="n">x</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Dataframe of review and topics</span>
<span class="n">data_new</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">data</span><span class="p">,</span><span class="n">document_topics</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">join</span><span class="o">=</span><span class="s1">'inner'</span><span class="p">)</span>
<span class="n">data_new</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>review</th>
      <th>Topic #1</th>
      <th>Topic #2</th>
      <th>Topic #3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>May be my first negative review about the prod...</td>
      <td>0.004879</td>
      <td>0.004542</td>
      <td>0.990579</td>
    </tr>
    <tr>
      <td>1</td>
      <td>It's very expensive but the quality you get is...</td>
      <td>0.084246</td>
      <td>0.831019</td>
      <td>0.084735</td>
    </tr>
    <tr>
      <td>2</td>
      <td>The iPhone design is good and the camera quali...</td>
      <td>0.696215</td>
      <td>0.133451</td>
      <td>0.170334</td>
    </tr>
    <tr>
      <td>3</td>
      <td>Awesome Phone. Nice upgrade from iPhone 6s to ...</td>
      <td>0.036537</td>
      <td>0.802536</td>
      <td>0.160927</td>
    </tr>
    <tr>
      <td>4</td>
      <td>My Phone is Producing Too Much Heat Even Didn’...</td>
      <td>0.567121</td>
      <td>0.010595</td>
      <td>0.422285</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Visualization-of-LDA-Model">
<a class="anchor" href="#Visualization-of-LDA-Model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Visualization of LDA Model<a class="anchor-link" href="#Visualization-of-LDA-Model"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>There is a nice way to visualize the LDA mode using the package pyLDAvis. This visualization allows us to compare topics on two reduced dimensions and observe the distribution of words in topics. The size of the bubble measures the importance of the topics, relative to the data.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pyLDAvis.gensim</span>
<span class="n">lda_display</span> <span class="o">=</span> <span class="n">pyLDAvis</span><span class="o">.</span><span class="n">gensim</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">ldamodel</span><span class="p">,</span> <span class="n">doc_term_matrix</span><span class="p">,</span> <span class="n">dictionary</span><span class="p">,</span> <span class="n">sort_topics</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">pyLDAvis</span><span class="o">.</span><span class="n">display</span><span class="p">(</span><span class="n">lda_display</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\61920959\AppData\Local\Continuum\anaconda3\lib\site-packages\pyLDAvis\_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version
of pandas will change to not sort by default.

To accept the future behavior, pass 'sort=False'.

To retain the current behavior and silence the warning, pass 'sort=True'.

  return pd.concat([default_term_info] + list(topic_dfs))
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">

<link rel="stylesheet" type="text/css" href="https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css">


<div id="ldavis_el2234027504190491603725671490"></div>
<script type="text/javascript">

var ldavis_el2234027504190491603725671490_data = {"mdsDat": {"x": [-0.049970095511477484, -0.11405233666446685, 0.16402243217594428], "y": [0.10368969529522765, -0.0797944383228046, -0.02389525697242302], "topics": [1, 2, 3], "cluster": [1, 1, 1], "Freq": [29.946571350097656, 47.069461822509766, 22.983964920043945]}, "tinfo": {"Category": ["Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3"], "Freq": [122.0, 58.0, 45.0, 332.0, 97.0, 165.0, 232.0, 111.0, 119.0, 35.0, 102.0, 98.0, 132.0, 47.0, 206.0, 18.0, 45.0, 175.0, 28.0, 20.0, 25.0, 51.0, 39.0, 29.0, 48.0, 22.0, 38.0, 69.0, 16.0, 17.0, 35.12144088745117, 11.336016654968262, 16.930837631225586, 9.58990478515625, 7.924757480621338, 7.084667682647705, 6.200098991394043, 8.432709693908691, 4.540863990783691, 4.533634185791016, 4.533117771148682, 4.529587745666504, 4.526539325714111, 4.504759311676025, 11.135407447814941, 4.445218086242676, 3.6899735927581787, 3.6898138523101807, 3.689311981201172, 3.6864449977874756, 3.684037208557129, 10.149643898010254, 3.63498592376709, 3.6318533420562744, 4.336184024810791, 2.8324713706970215, 2.8291420936584473, 2.826286554336548, 2.8246119022369385, 2.822077751159668, 16.61539649963379, 6.870250701904297, 11.179475784301758, 3.488116979598999, 24.218090057373047, 22.00723648071289, 23.925195693969727, 164.11692810058594, 116.76065826416016, 8.072484016418457, 10.517382621765137, 26.020395278930664, 15.517998695373535, 10.872183799743652, 41.59506607055664, 17.23969841003418, 9.335533142089844, 9.427763938903809, 38.0207405090332, 7.119644641876221, 14.271566390991211, 15.801105499267578, 15.878588676452637, 13.23153305053711, 14.050203323364258, 9.725032806396484, 13.011211395263672, 20.375988006591797, 20.449615478515625, 11.314496994018555, 15.612205505371094, 11.12274169921875, 10.637272834777832, 19.401201248168945, 21.059946060180664, 37.70634460449219, 43.425811767578125, 36.679264068603516, 92.15852355957031, 32.656856536865234, 8.949777603149414, 9.749029159545898, 8.09080982208252, 102.98834228515625, 6.36596155166626, 6.36587381362915, 6.3401923179626465, 93.16046905517578, 6.304343223571777, 89.7179183959961, 5.496222019195557, 17.274818420410156, 5.485782146453857, 5.4744791984558105, 5.441539764404297, 6.9764790534973145, 4.633158206939697, 4.632380485534668, 4.6250410079956055, 4.6245269775390625, 4.621087074279785, 4.614863395690918, 4.608479976654053, 146.39126586914062, 7.634081840515137, 143.66177368164062, 167.3839874267578, 22.05071258544922, 9.790714263916016, 39.83199691772461, 93.90030670166016, 25.162511825561523, 31.173505783081055, 34.11351776123047, 24.713565826416016, 27.268632888793945, 139.39170837402344, 24.187055587768555, 102.0161361694336, 14.878180503845215, 18.1270694732666, 22.581727981567383, 32.50726318359375, 17.712125778198242, 20.04178810119629, 21.064748764038086, 24.945833206176758, 18.610898971557617, 18.731321334838867, 121.58513641357422, 44.443119049072266, 56.318546295166016, 17.40280532836914, 10.904537200927734, 8.417844772338867, 6.824138641357422, 6.820992469787598, 6.001565933227539, 6.728668212890625, 5.170010566711426, 5.133111000061035, 4.365938663482666, 4.359323501586914, 14.441993713378906, 4.330189228057861, 5.746097087860107, 17.799787521362305, 3.5463764667510986, 3.5448479652404785, 3.5307064056396484, 3.4872117042541504, 3.4860053062438965, 5.561874866485596, 3.4695677757263184, 4.142392158508301, 2.729600429534912, 2.729445457458496, 2.724003553390503, 2.723945379257202, 7.921080112457275, 17.0975341796875, 20.786161422729492, 5.886320114135742, 17.94658851623535, 19.689311981201172, 27.87645149230957, 52.80519485473633, 8.11532974243164, 24.699357986450195, 28.53512191772461, 17.642528533935547, 17.619949340820312, 10.301884651184082, 19.32267189025879, 9.374361038208008, 10.676902770996094, 28.663801193237305, 10.626174926757812, 18.435199737548828, 11.342704772949219, 10.888626098632812, 9.95749568939209, 13.582184791564941, 9.080998420715332, 11.362668991088867, 9.374822616577148], "Term": ["product", "amazon", "nice", "phone", "life", "batteri", "good", "awesom", "appl", "charger", "qualiti", "great", "best", "monei", "iphon", "thank", "displai", "camera", "deliveri", "perfect", "devic", "time", "upgrad", "got", "excel", "happi", "perform", "bui", "receiv", "get", "charger", "problem", "get", "sim", "poor", "dual", "till", "model", "button", "set", "show", "scratch", "world", "fan", "word", "kind", "navig", "live", "finger", "stop", "automat", "support", "voic", "bulki", "plai", "ear", "variant", "earpod", "didn\u2019t", "caus", "purchas", "pixel", "hang", "len", "work", "charg", "issu", "phone", "good", "speaker", "low", "time", "heat", "bad", "appl", "screen", "box", "app", "best", "miss", "us", "android", "mobil", "experi", "like", "compar", "face", "camera", "iphon", "overal", "batteri", "fast", "io", "super", "recognit", "upgrad", "displai", "perform", "life", "superb", "simpli", "chang", "class", "awesom", "gui", "ol", "youtub", "qualiti", "beauti", "great", "process", "backup", "mark", "tech", "amol", "last", "won\u2019t", "major", "ultim", "decis", "speed", "notic", "clariti", "batteri", "big", "camera", "iphon", "feel", "improv", "amaz", "best", "better", "dai", "love", "look", "face", "phone", "it\u2019", "good", "featur", "pro", "android", "bui", "pictur", "overal", "fast", "appl", "screen", "monei", "product", "nice", "amazon", "thank", "return", "defect", "origin", "genuin", "seller", "worst", "penni", "real", "hard", "card", "receiv", "fulli", "airpod", "perfect", "pack", "soo", "repair", "accessori", "handl", "beast", "tri", "safe", "india", "phn", "restor", "higher", "ye", "happi", "deliveri", "damag", "devic", "got", "monei", "appl", "deliv", "excel", "bui", "worth", "valu", "servic", "time", "packag", "need", "phone", "price", "iphon", "amaz", "love", "mobil", "good", "expect", "camera", "like"], "Total": [122.0, 58.0, 45.0, 332.0, 97.0, 165.0, 232.0, 111.0, 119.0, 35.0, 102.0, 98.0, 132.0, 47.0, 206.0, 18.0, 45.0, 175.0, 28.0, 20.0, 25.0, 51.0, 39.0, 29.0, 48.0, 22.0, 38.0, 69.0, 16.0, 17.0, 35.76359558105469, 11.916610717773438, 17.882081985473633, 10.211921691894531, 8.5106840133667, 7.659251689910889, 6.80782413482666, 9.36913013458252, 5.104472637176514, 5.104535102844238, 5.1041579246521, 5.1041412353515625, 5.104562759399414, 5.104878902435303, 12.731779098510742, 5.106123447418213, 4.252901554107666, 4.252893447875977, 4.252857208251953, 4.252876281738281, 4.252679824829102, 11.872123718261719, 4.25288200378418, 4.252882480621338, 5.0980072021484375, 3.401109218597412, 3.4011151790618896, 3.4008755683898926, 3.4006755352020264, 3.4014344215393066, 20.49448013305664, 8.526926040649414, 14.528589248657227, 4.2458062171936035, 33.89475631713867, 31.517194747924805, 35.693843841552734, 332.17242431640625, 232.35897827148438, 10.973384857177734, 15.34045124053955, 51.30286407470703, 27.132061004638672, 18.010652542114258, 119.34609985351562, 36.1407585144043, 15.117147445678711, 15.39788818359375, 132.22842407226562, 10.231888771057129, 31.689992904663086, 38.77383804321289, 39.920684814453125, 30.67198371887207, 41.73460388183594, 18.038650512695312, 40.57783126831055, 175.4004364013672, 206.268798828125, 34.359214782714844, 165.5483856201172, 38.506690979003906, 29.21755599975586, 19.977001190185547, 21.71460723876953, 39.07049560546875, 45.171630859375, 38.2182502746582, 97.27674865722656, 34.72608947753906, 9.540315628051758, 10.4097261428833, 8.671884536743164, 111.93212127685547, 6.933274269104004, 6.933246612548828, 6.932362079620361, 102.37646484375, 6.930593967437744, 98.9018325805664, 6.063632965087891, 19.07653045654297, 6.062727928161621, 6.06292724609375, 6.0615668296813965, 7.7973952293396, 5.194256782531738, 5.194185733795166, 5.193580627441406, 5.19363260269165, 5.193571090698242, 5.193787097930908, 5.1932597160339355, 165.5483856201172, 8.645147323608398, 175.4004364013672, 206.268798828125, 25.993017196655273, 11.261902809143066, 51.47015380859375, 132.22842407226562, 31.971139907836914, 43.869014739990234, 48.814693450927734, 33.71080780029297, 40.57783126831055, 332.17242431640625, 36.90200424194336, 232.35897827148438, 20.626480102539062, 27.611610412597656, 38.77383804321289, 69.37051391601562, 27.59894371032715, 34.359214782714844, 38.506690979003906, 119.34609985351562, 36.1407585144043, 47.82099533081055, 122.9312515258789, 45.0786247253418, 58.23370361328125, 18.050472259521484, 11.49491024017334, 9.039051055908203, 7.399076461791992, 7.399190902709961, 6.580202102661133, 7.40452766418457, 5.761588096618652, 5.763891696929932, 4.941909313201904, 4.942131519317627, 16.463953018188477, 4.943872451782227, 6.590208053588867, 20.61334991455078, 4.122890472412109, 4.122971057891846, 4.123410701751709, 4.125059604644775, 4.126185417175293, 6.606701374053955, 4.125945091247559, 4.955117225646973, 3.3037238121032715, 3.3037142753601074, 3.304009437561035, 3.3039755821228027, 9.939166069030762, 22.394773483276367, 28.207775115966797, 7.436105728149414, 25.843294143676758, 29.10215950012207, 47.82099533081055, 119.34609985351562, 11.609298706054688, 48.797157287597656, 69.37051391601562, 37.12312698364258, 37.1492919921875, 18.365398406982422, 51.30286407470703, 17.597816467285156, 24.428525924682617, 332.17242431640625, 34.77949523925781, 206.268798828125, 51.47015380859375, 48.814693450927734, 39.920684814453125, 232.35897827148438, 27.071792602539062, 175.4004364013672, 41.73460388183594], "loglift": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.187600016593933, 1.1557999849319458, 1.1511000394821167, 1.142899990081787, 1.1344000101089478, 1.1277999877929688, 1.1122000217437744, 1.1004999876022339, 1.0887999534606934, 1.0871000289916992, 1.0871000289916992, 1.086300015449524, 1.0856000185012817, 1.0807000398635864, 1.0717999935150146, 1.0671000480651855, 1.0637999773025513, 1.0636999607086182, 1.063599944114685, 1.0628000497817993, 1.0621999502182007, 1.0490000247955322, 1.048799991607666, 1.0478999614715576, 1.0439000129699707, 1.0227999687194824, 1.0216000080108643, 1.0206999778747559, 1.0202000141143799, 1.0190000534057617, 0.9958999752998352, 0.9897000193595886, 0.9437000155448914, 1.0091999769210815, 0.8695999979972839, 0.8465999960899353, 0.8057000041007996, 0.5006999969482422, 0.5175999999046326, 0.8986999988555908, 0.8282999992370605, 0.5268999934196472, 0.6470000147819519, 0.7009999752044678, 0.1517000049352646, 0.46549999713897705, 0.723800003528595, 0.7152000069618225, -0.0406000018119812, 0.8431000113487244, 0.40799999237060547, 0.30809998512268066, 0.28380000591278076, 0.36500000953674316, 0.11710000038146973, 0.5878999829292297, 0.06830000132322311, -0.9470000267028809, -1.1054999828338623, 0.0949999988079071, -1.155500054359436, -0.03610000014305115, 0.19529999792575836, 0.7243000268936157, 0.7228999733924866, 0.7179999947547913, 0.7141000032424927, 0.7124000191688538, 0.6995000243186951, 0.6920999884605408, 0.6895999908447266, 0.6880000233650208, 0.6841999888420105, 0.6703000068664551, 0.6682000160217285, 0.6682000160217285, 0.6643000245094299, 0.6592000126838684, 0.6588000059127808, 0.6560999751091003, 0.6553000211715698, 0.6542999744415283, 0.6535000205039978, 0.6514999866485596, 0.6456000208854675, 0.642300009727478, 0.63919997215271, 0.6391000151634216, 0.6376000046730042, 0.637499988079071, 0.6367999911308289, 0.6353999972343445, 0.6341000199317932, 0.6305999755859375, 0.6291999816894531, 0.5539000034332275, 0.544700026512146, 0.5891000032424927, 0.6136000156402588, 0.49720001220703125, 0.41119998693466187, 0.5141000151634216, 0.41190001368522644, 0.3952000141143799, 0.4431000053882599, 0.3560999929904938, -0.11479999870061874, 0.3310999870300293, -0.06960000097751617, 0.4268999993801117, 0.3327000141143799, 0.21289999783039093, -0.0044999998062849045, 0.3100000023841858, 0.21449999511241913, 0.15029999613761902, -0.8118000030517578, 0.08990000188350677, -0.18369999527931213, 1.4594000577926636, 1.4562000036239624, 1.436900019645691, 1.4337999820709229, 1.4176000356674194, 1.3991999626159668, 1.3895000219345093, 1.3890000581741333, 1.3782999515533447, 1.3746999502182007, 1.3619999885559082, 1.3545000553131104, 1.346500039100647, 1.3449000120162964, 1.3393000364303589, 1.3378000259399414, 1.333299994468689, 1.3236000537872314, 1.319700002670288, 1.3193000555038452, 1.3151999711990356, 1.30239999294281, 1.301800012588501, 1.298200011253357, 1.2970999479293823, 1.291200041770935, 1.2795000076293945, 1.2793999910354614, 1.2773000001907349, 1.2773000001907349, 1.243399977684021, 1.2005000114440918, 1.1650999784469604, 1.2367000579833984, 1.1057000160217285, 1.0795999765396118, 0.9307000041007996, 0.6549999713897705, 1.1123000383377075, 0.7894999980926514, 0.5820000171661377, 0.7264000177383423, 0.7245000004768372, 0.8921999931335449, 0.49390000104904175, 0.8406000137329102, 0.6427000164985657, -0.9796000123023987, 0.2847000062465668, -0.9445000290870667, -0.042100001126527786, -0.029899999499320984, 0.08179999887943268, -1.3691999912261963, 0.3781000077724457, -1.2663999795913696, -0.02290000021457672], "logprob": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.257199764251709, -5.388000011444092, -4.986800193786621, -5.555300235748291, -5.745999813079834, -5.857999801635742, -5.991399765014648, -5.683800220489502, -6.302800178527832, -6.3043999671936035, -6.304599761962891, -6.305300235748291, -6.306000232696533, -6.310800075531006, -5.405799865722656, -6.324100017547607, -6.510300159454346, -6.51039981842041, -6.510499954223633, -6.511300086975098, -6.51200008392334, -5.498499870300293, -6.525400161743164, -6.526199817657471, -6.348999977111816, -6.774799823760986, -6.776000022888184, -6.7769999504089355, -6.777599811553955, -6.778500080108643, -5.0055999755859375, -5.888800144195557, -5.401899814605713, -6.5665998458862305, -4.628900051116943, -4.724599838256836, -4.640999794006348, -2.715399980545044, -3.055799961090088, -5.727499961853027, -5.462900161743164, -4.55709981918335, -5.073999881744385, -5.429800033569336, -4.0879998207092285, -4.968699932098389, -5.582099914550781, -5.572299957275391, -4.177800178527832, -5.853099822998047, -5.157700061798096, -5.0559000968933105, -5.051000118255615, -5.233399868011475, -5.173299789428711, -5.541299819946289, -5.250199794769287, -4.801599979400635, -4.797999858856201, -5.389900207519531, -5.06790018081665, -5.4070000648498535, -5.451600074768066, -5.302800178527832, -5.220799922943115, -4.638299942016602, -4.497099876403809, -4.665999889373779, -3.7446999549865723, -4.782100200653076, -6.076499938964844, -5.991000175476074, -6.1774001121521, -3.6335999965667725, -6.417200088500977, -6.417200088500977, -6.421299934387207, -3.733799934387207, -6.4268999099731445, -3.7715001106262207, -6.5640997886657715, -5.418900012969971, -6.565999984741211, -6.5680999755859375, -6.574100017547607, -6.3256001472473145, -6.734899997711182, -6.735099792480469, -6.736700057983398, -6.736800193786621, -6.737500190734863, -6.738900184631348, -6.740300178527832, -3.281899929046631, -6.235599994659424, -3.3006999492645264, -3.147900104522705, -5.174799919128418, -5.986700057983398, -4.583499908447266, -3.7258999347686768, -5.042799949645996, -4.82859992980957, -4.738500118255615, -5.060800075531006, -4.962399959564209, -3.330899953842163, -5.082399845123291, -3.6429998874664307, -5.568299770355225, -5.370800018310547, -5.151000022888184, -4.7866997718811035, -5.393899917602539, -5.270400047302246, -5.220600128173828, -5.051499843597412, -5.344399929046631, -5.3379998207092285, -2.750699996948242, -3.7571001052856445, -3.5202999114990234, -4.694699764251709, -5.162199974060059, -5.421000003814697, -5.630899906158447, -5.63129997253418, -5.759300231933594, -5.644999980926514, -5.9085001945495605, -5.915599822998047, -6.077499866485596, -6.078999996185303, -4.881199836730957, -6.085700035095215, -5.802800178527832, -4.6722002029418945, -6.285399913787842, -6.285799980163574, -6.28980016708374, -6.302199840545654, -6.302599906921387, -5.835400104522705, -6.307300090789795, -6.130099773406982, -6.5472002029418945, -6.5472002029418945, -6.549200057983398, -6.549300193786621, -5.481800079345703, -4.712399959564209, -4.517099857330322, -5.77869987487793, -4.663899898529053, -4.571300029754639, -4.223599910736084, -3.584700107574463, -5.457600116729736, -4.344600200653076, -4.200200080871582, -4.681000232696533, -4.682300090789795, -5.218999862670898, -4.590099811553955, -5.313399791717529, -5.183300018310547, -4.195700168609619, -5.188000202178955, -4.6371002197265625, -5.122799873352051, -5.163599967956543, -5.252999782562256, -4.942599773406982, -5.345200061798096, -5.120999813079834, -5.313300132751465]}, "token.table": {"Topic": [3, 1, 3, 2, 3, 1, 3, 2, 1, 2, 1, 2, 3, 1, 2, 3, 1, 1, 2, 3, 1, 2, 1, 2, 1, 2, 3, 2, 3, 2, 1, 2, 1, 2, 3, 2, 3, 1, 3, 1, 2, 3, 1, 1, 1, 2, 3, 3, 1, 2, 1, 2, 3, 1, 2, 2, 1, 2, 1, 2, 3, 1, 3, 2, 3, 1, 3, 1, 2, 3, 2, 3, 1, 1, 2, 1, 1, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 1, 1, 2, 3, 1, 2, 3, 1, 2, 1, 3, 3, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 3, 1, 2, 1, 2, 3, 3, 1, 2, 3, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 1, 2, 1, 1, 2, 1, 2, 3, 1, 1, 2, 1, 2, 3, 1, 2, 3, 2, 2, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 3, 1, 1, 2, 3, 3, 2, 2, 3, 1, 2, 3, 3, 1, 2, 3, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 1, 1, 1, 2, 3, 1, 2, 1, 2, 2, 3, 1, 2, 1, 2, 3, 3, 1, 3, 2, 3, 3, 3, 2, 3, 1, 1, 2, 3, 1, 2, 3, 1, 1, 1, 2, 3, 1, 3, 2, 1, 2, 1, 2, 1, 3, 2, 3, 1, 1, 2, 3, 3, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 1, 2, 1, 3, 1, 2, 3, 1, 3, 1, 2, 3, 2, 3, 2], "Freq": [0.7272621989250183, 0.15174028277397156, 0.9104416370391846, 0.7771494388580322, 0.21371608972549438, 0.034344371408224106, 0.9616424441337585, 0.8248692154884338, 0.41264936327934265, 0.5931834578514099, 0.5844957232475281, 0.3247198462486267, 0.06494396924972534, 0.35191765427589417, 0.20947480201721191, 0.44408658146858215, 0.9405834078788757, 0.06253790110349655, 0.920200526714325, 0.008933985605835915, 0.05242043361067772, 0.8911473751068115, 0.6107496619224548, 0.38865888118743896, 0.09664848446846008, 0.881917417049408, 0.02416212111711502, 0.15136146545410156, 0.9081687927246094, 0.8657266497612, 0.28738147020339966, 0.7108910083770752, 0.15639103949069977, 0.7819552421569824, 0.031278207898139954, 0.9253746271133423, 0.11567182838916779, 0.595350444316864, 0.3307502269744873, 0.1153227761387825, 0.47570642828941345, 0.4180450439453125, 0.9405385851860046, 0.9795331358909607, 0.1140248030424118, 0.820978581905365, 0.0627136379480362, 0.8093673586845398, 0.881980836391449, 0.9606400728225708, 0.6980316638946533, 0.1903722733259201, 0.09518613666296005, 0.9786487817764282, 0.9627864360809326, 0.9225215315818787, 0.5543652176856995, 0.4434921443462372, 0.15956592559814453, 0.706649124622345, 0.1139756590127945, 0.13447898626327515, 0.8068739771842957, 0.9627172946929932, 0.8850486278533936, 0.25841355323791504, 0.6891027688980103, 0.14180487394332886, 0.14180487394332886, 0.7444756031036377, 0.30955806374549866, 0.696505606174469, 0.8821776509284973, 0.02213778905570507, 0.9519249200820923, 0.9139273762702942, 0.8820651769638062, 0.8821257948875427, 0.10246498882770538, 0.3893669545650482, 0.5123249292373657, 0.332449346780777, 0.332449346780777, 0.332449346780777, 0.4238395690917969, 0.3912365138530731, 0.19561825692653656, 0.32037198543548584, 0.6653879284858704, 0.9794551730155945, 0.2856646478176117, 0.5453597903251648, 0.15581707656383514, 0.1454441100358963, 0.7272205352783203, 0.1454441100358963, 0.15388748049736023, 0.8463811874389648, 0.9405441284179688, 0.8090823888778687, 0.9460493922233582, 0.9506723284721375, 0.055921901017427444, 0.5035312175750732, 0.4389759302139282, 0.06025159731507301, 0.20617026090621948, 0.13744685053825378, 0.6872342228889465, 0.0808882862329483, 0.9099932312965393, 0.010111035779118538, 0.8653919696807861, 0.727063775062561, 0.7571278810501099, 0.2064894288778305, 0.0446532741189003, 0.1786130964756012, 0.7591056823730469, 0.8094037771224976, 0.5897082686424255, 0.22114059329032898, 0.22114059329032898, 0.9079970121383667, 0.08879493921995163, 0.8879494071006775, 0.9080662131309509, 0.3764859735965729, 0.5818419456481934, 0.06845199316740036, 0.09696085751056671, 0.8096231818199158, 0.0872647762298584, 0.6723848581314087, 0.1961122453212738, 0.14008018374443054, 0.18969158828258514, 0.6503711938858032, 0.13549399375915527, 0.7833731770515442, 0.1282479614019394, 0.8977357149124146, 0.7065795660018921, 0.05139974504709244, 0.9457553029060364, 0.3354530334472656, 0.43129676580429077, 0.21564838290214539, 0.9405361413955688, 0.2669766843318939, 0.7416019439697266, 0.08194254338741302, 0.6965115666389465, 0.22534199059009552, 0.7170584201812744, 0.19556139409542084, 0.06518713384866714, 0.9626147747039795, 0.824711263179779, 0.6841356754302979, 0.19546733796596527, 0.09773366898298264, 0.40079471468925476, 0.35069540143013, 0.2504967153072357, 0.8538679480552673, 0.10673349350690842, 0.020911317318677902, 0.39731502532958984, 0.5855168700218201, 0.9405343532562256, 0.24561449885368347, 0.32748597860336304, 0.45029324293136597, 0.976072371006012, 0.962688684463501, 0.8653954267501831, 0.9460639953613281, 0.32014700770378113, 0.5820854902267456, 0.08731282502412796, 0.9701931476593018, 0.22730092704296112, 0.22730092704296112, 0.511427104473114, 0.8678162693977356, 0.04851225018501282, 0.09702450037002563, 0.8732205033302307, 0.026165509596467018, 0.9681238532066345, 0.908068835735321, 0.4937194883823395, 0.41845735907554626, 0.08730405569076538, 0.3260994255542755, 0.652198851108551, 0.8209288716316223, 0.11727555841207504, 0.7846202850341797, 0.9399949312210083, 0.2875257432460785, 0.4025360345840454, 0.3162783086299896, 0.32594984769821167, 0.6518996953964233, 0.9230812788009644, 0.8245881795883179, 0.008134627714753151, 0.9924246072769165, 0.8294916152954102, 0.14638087153434753, 0.07814296334981918, 0.9084119200706482, 0.009767870418727398, 0.8674694299697876, 0.12147750705480576, 0.8503425717353821, 0.9670909643173218, 0.9700707197189331, 0.9079877138137817, 0.9569453001022339, 0.20181156694889069, 0.8072462677955627, 0.979596734046936, 0.47038304805755615, 0.5257222056388855, 0.9118260741233826, 0.3267013132572174, 0.10890044271945953, 0.5445021986961365, 0.9795211553573608, 0.9795935153961182, 0.9792476296424866, 0.9433650374412537, 0.9701741933822632, 0.7290366888046265, 0.27338874340057373, 0.96272873878479, 0.9405399560928345, 0.9510936737060547, 0.057593584060668945, 0.9502941370010376, 0.842309296131134, 0.0842309296131134, 0.8246841430664062, 0.9418036341667175, 0.881338894367218, 0.5067943334579468, 0.11695253849029541, 0.3703497052192688, 0.7271061539649963, 0.9627269506454468, 0.025594761595129967, 0.9726009368896484, 0.025594761595129967, 0.44177985191345215, 0.44177985191345215, 0.09466710686683655, 0.02691841311752796, 0.484531432390213, 0.484531432390213, 0.882063627243042, 0.9405386447906494, 0.9626016020774841, 0.8639798164367676, 0.07854361832141876, 0.708074152469635, 0.11801235377788544, 0.17701853811740875, 0.9795158505439758, 0.9453675150871277, 0.053874772042036057, 0.4579355716705322, 0.4848729372024536, 0.20122411847114563, 0.8048964738845825, 0.8655058741569519], "Term": ["accessori", "airpod", "airpod", "amaz", "amaz", "amazon", "amazon", "amol", "android", "android", "app", "app", "app", "appl", "appl", "appl", "automat", "awesom", "awesom", "awesom", "backup", "backup", "bad", "bad", "batteri", "batteri", "batteri", "beast", "beast", "beauti", "best", "best", "better", "better", "better", "big", "big", "box", "box", "bui", "bui", "bui", "bulki", "button", "camera", "camera", "camera", "card", "caus", "chang", "charg", "charg", "charg", "charger", "clariti", "class", "compar", "compar", "dai", "dai", "dai", "damag", "damag", "decis", "defect", "deliv", "deliv", "deliveri", "deliveri", "deliveri", "devic", "devic", "didn\u2019t", "displai", "displai", "dual", "ear", "earpod", "excel", "excel", "excel", "expect", "expect", "expect", "experi", "experi", "experi", "face", "face", "fan", "fast", "fast", "fast", "featur", "featur", "featur", "feel", "feel", "finger", "fulli", "genuin", "get", "get", "good", "good", "good", "got", "got", "got", "great", "great", "great", "gui", "handl", "hang", "hang", "happi", "happi", "happi", "hard", "heat", "heat", "heat", "higher", "improv", "improv", "india", "io", "io", "io", "iphon", "iphon", "iphon", "issu", "issu", "issu", "it\u2019", "it\u2019", "it\u2019", "kind", "last", "last", "len", "life", "life", "like", "like", "like", "live", "look", "look", "love", "love", "love", "low", "low", "low", "major", "mark", "miss", "miss", "miss", "mobil", "mobil", "mobil", "model", "model", "monei", "monei", "monei", "navig", "need", "need", "need", "nice", "notic", "ol", "origin", "overal", "overal", "overal", "pack", "packag", "packag", "packag", "penni", "perfect", "perfect", "perfect", "perform", "perform", "phn", "phone", "phone", "phone", "pictur", "pictur", "pixel", "pixel", "plai", "poor", "price", "price", "price", "pro", "pro", "problem", "process", "product", "product", "purchas", "purchas", "qualiti", "qualiti", "qualiti", "real", "receiv", "receiv", "recognit", "repair", "restor", "return", "safe", "safe", "scratch", "screen", "screen", "seller", "servic", "servic", "servic", "set", "show", "sim", "simpli", "soo", "speaker", "speaker", "speed", "stop", "super", "superb", "superb", "support", "support", "tech", "thank", "till", "time", "time", "time", "tri", "ultim", "upgrad", "upgrad", "upgrad", "us", "us", "us", "valu", "valu", "valu", "variant", "voic", "won\u2019t", "word", "word", "work", "work", "work", "world", "worst", "worth", "worth", "worth", "ye", "ye", "youtub"]}, "R": 30, "lambda.step": 0.01, "plot.opts": {"xlab": "PC1", "ylab": "PC2"}, "topic.order": [1, 2, 3]};

function LDAvis_load_lib(url, callback){
  var s = document.createElement('script');
  s.src = url;
  s.async = true;
  s.onreadystatechange = s.onload = callback;
  s.onerror = function(){console.warn("failed to load library " + url);};
  document.getElementsByTagName("head")[0].appendChild(s);
}

if(typeof(LDAvis) !== "undefined"){
   // already loaded: just create the visualization
   !function(LDAvis){
       new LDAvis("#" + "ldavis_el2234027504190491603725671490", ldavis_el2234027504190491603725671490_data);
   }(LDAvis);
}else if(typeof define === "function" && define.amd){
   // require.js is available: use it to load d3/LDAvis
   require.config({paths: {d3: "https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min"}});
   require(["d3"], function(d3){
      window.d3 = d3;
      LDAvis_load_lib("https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js", function(){
        new LDAvis("#" + "ldavis_el2234027504190491603725671490", ldavis_el2234027504190491603725671490_data);
      });
    });
}else{
    // require.js not available: dynamically load d3 & LDAvis
    LDAvis_load_lib("https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js", function(){
         LDAvis_load_lib("https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js", function(){
                 new LDAvis("#" + "ldavis_el2234027504190491603725671490", ldavis_el2234027504190491603725671490_data);
            })
         });
}
</script>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Endnotes">
<a class="anchor" href="#Endnotes" aria-hidden="true"><span class="octicon octicon-link"></span></a>Endnotes<a class="anchor-link" href="#Endnotes"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>I hope this blog helps in understanding how powerful Topic Modeling is in understanding unstructured textual data.  Feel free to play around with the code by opening in Colab or cloning the repo in github.</p>
<p>If you have any comments or suggestions please comment below or reach out to me at - <a href="https://twitter.com/rahulsingla0959">Twitter</a> or <a href="https://www.linkedin.com/in/rahul-singla1/">LinkedIn</a></p>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="rahuls0959/ds-blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/ds-blog/python/text%20analytics/web%20scraping/topic%20modeling/selenium/gensim/nlp/2020/04/19/_Topic_Modeling_Amazon_Reviews.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/ds-blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/ds-blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/ds-blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Personal website for Analytics Projects</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/rahuls0959" title="rahuls0959"><svg class="svg-icon grey"><use xlink:href="/ds-blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/rahulsingla0959" title="rahulsingla0959"><svg class="svg-icon grey"><use xlink:href="/ds-blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
